"""
Agentic Memory Bank æ ¸å¿ƒç±»

æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œæä¾›å®Œæ•´çš„è®°å¿†ç®¡ç†åŠŸèƒ½ã€‚

è§„èŒƒæ–‡æ¡£ï¼šç¬¬8ç« 
"""

import logging
import uuid
import time
from typing import Dict, Any, List, Optional, Tuple

from src.storage.insight_doc import InsightDoc, CompletedTask, TaskType
from src.storage.query_graph import QueryGraph, QueryGraphNode
from src.storage.interaction_tree import InteractionTree, create_entry
from src.modules.embedding import EmbeddingModule
from src.modules.retrieval import RetrievalModule
from src.modules.graph_ops import GraphOperations
from src.modules.context_update import ContextUpdateModule
from src.agents.classification_agent import ClassificationAgent, ClassificationInput
from src.agents.structure_agent import StructureAgent, StructureInput
from src.agents.analysis_agent import AnalysisAgent, AnalysisInput
from src.agents.integration_agent import IntegrationAgent, IntegrationInput, NodeWithNeighbors
from src.agents.planning_agent import PlanningAgent, PlanningInput, ConflictNotification
from src.interface.adapter import MemoryBankAdapter
from src.tools.deep_retrieval_tool import DeepRetrievalTool
from src.tools.search_tool import SearchTool
from src.tools.visit_tool import VisitTool
from src.tools.react_agent import MultiTurnReactAgent
from src.utils.llm_client import LLMClient
from src.utils.file_utils import FileUtils
from src.config import Config
from src.prompts.agent_prompts import REACT_SYSTEM_PROMPT

logger = logging.getLogger(__name__)


class MemoryBank:
    """Agentic Memory Bankä¸»ç±»"""

    def __init__(self, config: Config = None):
        """
        åˆå§‹åŒ–Memory Bank

        Args:
            config: é…ç½®å¯¹è±¡ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
        """
        logger.info("åˆå§‹åŒ–Agentic Memory Bank...")

        # åˆå§‹åŒ–é…ç½®
        self.config = config or Config()

        # åˆå§‹åŒ–å­˜å‚¨å±‚
        self.query_graph = QueryGraph()
        self.interaction_tree = InteractionTree()
        self.insight_doc = None  # æ¯æ¬¡ä»»åŠ¡å•ç‹¬åˆ›å»º

        # åˆå§‹åŒ–å·¥å…·
        self.llm_client = LLMClient.from_config(self.config)
        self.file_utils = FileUtils(
            temp_dir=self.config.TEMP_DIR,
            storage_dir=self.config.STORAGE_DIR
        )

        # åˆå§‹åŒ–ç¡¬ç¼–ç æ¨¡å—
        self.embedding_module = EmbeddingModule.from_config(self.config)
        self.retrieval_module = RetrievalModule(
            alpha=self.config.RETRIEVAL_ALPHA,
            k=self.config.RETRIEVAL_K
        )
        self.graph_ops = GraphOperations(self.query_graph)
        self.context_updater = ContextUpdateModule(self.query_graph, self.embedding_module)

        # åˆå§‹åŒ–Agent
        self.classification_agent = ClassificationAgent.from_config(
            self.llm_client, self.config
        )
        self.structure_agent = StructureAgent.from_config(self.llm_client, self.config)
        self.analysis_agent = AnalysisAgent.from_config(self.llm_client, self.config)
        self.integration_agent = IntegrationAgent.from_config(self.llm_client, self.config)
        self.planning_agent = PlanningAgent.from_config(self.llm_client, self.config)

        # åˆå§‹åŒ–Interfaceå±‚
        self.deep_retrieval_tool = DeepRetrievalTool(self.interaction_tree, self.file_utils)

        # æœç´¢å·¥å…·ï¼šå¦‚æœé…ç½®äº†Serper API keyï¼Œä½¿ç”¨çœŸå®æœç´¢
        search_api_key = self.config.SERPER_API_KEY
        if not search_api_key or search_api_key == "your-serper-api-key-here":
            raise ValueError(
                "æœªé…ç½®Serper API keyã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®SERPER_API_KEYã€‚\n"
                "æ³¨å†Œåœ°å€ï¼šhttps://serper.dev/"
            )

        self.search_tool = SearchTool(search_api_key=search_api_key)

        # Visitå·¥å…·ï¼šå¦‚æœé…ç½®äº†Jina API keyï¼Œä½¿ç”¨Jina Readerï¼›å¦åˆ™ä½¿ç”¨BeautifulSoup
        jina_api_key = self.config.JINA_API_KEY
        self.visit_tool = VisitTool(
            llm_client=self.llm_client,
            jina_api_key=jina_api_key
        )

        # åˆå§‹åŒ–Adapter
        self.adapter = MemoryBankAdapter(self, self.retrieval_module, self.file_utils)

        # åˆå§‹åŒ–ReAct Agent
        tools = {
            "deep_retrieval": self.deep_retrieval_tool,
            "search": self.search_tool,
            "visit": self.visit_tool
        }
        self.react_agent = MultiTurnReactAgent(
            llm_client=self.llm_client,
            tools=tools,
            system_message=REACT_SYSTEM_PROMPT,
            max_iterations=self.config.MAX_LLM_CALL_PER_RUN,
            max_context_tokens=self.config.MAX_CONTEXT_TOKENS
        )

        logger.info("Agentic Memory Bankåˆå§‹åŒ–å®Œæˆ")

    def run(self, user_input: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•æ¬¡ä»»åŠ¡

        Args:
            user_input: ç”¨æˆ·è¾“å…¥ï¼ˆå¯èƒ½åŒ…å«ä¸Šä¸‹æ–‡+é—®é¢˜ï¼‰

        Returns:
            ä»»åŠ¡ç»“æœï¼š{
                "answer": str,
                "insight_doc": dict,
                "stats": dict
            }
        """
        logger.info("=" * 60)
        logger.info(f"å¼€å§‹æ–°ä»»åŠ¡: {user_input[:100]}...")
        logger.info("=" * 60)

        try:
            # 1. åˆå§‹åŒ–é˜¶æ®µ
            print("\n" + "ğŸš€ " + "=" * 68)
            print("  Agentic Memory Bank - åˆå§‹åŒ–")
            print("=" * 70)
            enhanced_prompt = self._initialize(user_input)
            iterations = 0

            # æ˜¾ç¤ºä»»åŠ¡ç›®æ ‡å’Œåˆå§‹çŠ¶æ€
            if self.insight_doc:
                print(f"\nğŸ“‹ ä»»åŠ¡ç›®æ ‡: {self.insight_doc.task_goal}")
                print(f"ğŸ“ å¾…åŠä»»åŠ¡: {self.insight_doc.pending_tasks}")
                print("=" * 70)

            # 2. æ‰§è¡Œå¾ªç¯
            answer = None
            last_react_result = None  # ä¿å­˜æœ€åä¸€æ¬¡ReActç»“æœ
            max_iterations = self.config.MAX_LLM_CALL_PER_RUN
            while not self._should_terminate() and iterations < max_iterations:
                iterations += 1
                print(f"\n{'ğŸ”„ ' + '=' * 68}")
                print(f"  æ‰§è¡Œè½®æ¬¡ {iterations}")
                print("=" * 70)
                logger.info(f"\n----- æ‰§è¡Œè½®æ¬¡ {iterations} -----")

                # æ˜¾ç¤ºå½“å‰ä»»åŠ¡çŠ¶æ€
                if self.insight_doc:
                    if self.insight_doc.pending_tasks:
                        print(f"â³ å½“å‰ä»»åŠ¡: {self.insight_doc.pending_tasks[0]}")
                    print(f"âœ… å·²å®Œæˆ: {len(self.insight_doc.completed_tasks)} ä¸ªä»»åŠ¡")
                    print(f"ğŸ“Š è®°å¿†èŠ‚ç‚¹: {self.query_graph.get_node_count()} ä¸ª")

                # 2.1 ReActæ‰§è¡Œ
                react_result = self.react_agent.run(enhanced_prompt)
                last_react_result = react_result  # ä¿å­˜ç»“æœ
                answer = react_result.get("prediction", "")

                logger.info(f"ReActç»ˆæ­¢åŸå› : {react_result.get('termination')}")

                # 2.2 ä¸Šä¸‹æ–‡æ‹¦æˆªï¼šæå–æœç´¢ç»“æœå¹¶è½¬åŒ–ä¸ºè®°å¿†
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆå›ç­”ä»»åŠ¡
                current_task = self.insight_doc.pending_tasks[0] if self.insight_doc and self.insight_doc.pending_tasks else ""
                is_final_answer_task = "æ ¹æ®ç°æœ‰ç›¸å…³è®°å¿†ç›´æ¥å›ç­”é—®é¢˜" in current_task or "æ ¹æ®ç°æœ‰è®°å¿†å›ç­”é—®é¢˜" in current_task

                if self.insight_doc and self.insight_doc.pending_tasks:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼ˆé€šè¿‡æ£€æŸ¥æ¶ˆæ¯å†å²ï¼‰
                    messages = react_result.get("messages", [])
                    has_tool_calls = any(
                        msg.get("role") == "assistant" and "<tool_call>" in msg.get("content", "")
                        for msg in messages
                    )

                    tool_responses = self._extract_tool_responses(messages)

                    if has_tool_calls and not is_final_answer_task:
                        # æœ‰å·¥å…·è°ƒç”¨ï¼Œä¸”ä¸æ˜¯æœ€ç»ˆå›ç­”ä»»åŠ¡ - è¿›å…¥è®°å¿†å¤„ç†æµç¨‹
                        print(f"\nğŸ§  å¼€å§‹æ•´ç†è®°å¿†...")
                        logger.info(f"å¼€å§‹æ•´ç†è®°å¿†ï¼šæå–å®Œæ•´ä¸Šä¸‹æ–‡å¹¶è½¬åŒ–ä¸ºè®°å¿†èŠ‚ç‚¹")

                        # æå–å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬æ€è€ƒè¿‡ç¨‹ã€å·¥å…·è°ƒç”¨å’Œå·¥å…·å“åº”ï¼‰
                        full_context = self._extract_full_context(messages)
                        logger.debug(f"å®Œæ•´ä¸Šä¸‹æ–‡é•¿åº¦: {len(full_context)} å­—ç¬¦")

                        # è°ƒç”¨ä¸Šä¸‹æ–‡æ‹¦æˆªæœºåˆ¶
                        try:
                            # åˆ¤æ–­ä»»åŠ¡ç±»å‹ï¼ˆå‚è€ƒ REQUIREMENTS_FINAL.md ç¬¬4.2èŠ‚ï¼‰
                            if "éªŒè¯" in current_task or "Cross Validation" in current_task or "äº¤å‰éªŒè¯" in current_task:
                                task_type = "CROSS_VALIDATE"
                            else:
                                task_type = "NORMAL"

                            logger.info(f"ä»»åŠ¡ç±»å‹: {task_type}, å½“å‰ä»»åŠ¡: {current_task}")

                            # intercept_context å†…éƒ¨ä¼šè°ƒç”¨ Planning Agent æ›´æ–° insight_doc
                            # åŒ…æ‹¬ completed_tasks å’Œ pending_tasks
                            self.adapter.intercept_context(full_context, task_type, self.insight_doc)

                            print(f"âœ… è®°å¿†å¤„ç†å®Œæˆ")
                            logger.info(f"è®°å¿†å¤„ç†å®Œæˆï¼Œå¾…åŠä»»åŠ¡={len(self.insight_doc.pending_tasks)}")

                        except Exception as e:
                            print(f"âŒ é”™è¯¯: {str(e)}")
                            logger.error(f"ä¸Šä¸‹æ–‡æ‹¦æˆªå¤±è´¥: {str(e)}")
                            import traceback
                            traceback.print_exc()

                    elif is_final_answer_task and react_result.get("termination") == "answer":
                        # âœ… ä¿®å¤ï¼šæœ€ç»ˆå›ç­”ä»»åŠ¡ä¸”æœ‰ç­”æ¡ˆ - ç›´æ¥ä¿å­˜ç­”æ¡ˆå¹¶ç»“æŸ
                        answer = react_result.get("prediction", "")  # â† ä»predictionå­—æ®µè·å–
                        print("\nâœ… è·å¾—æœ€ç»ˆç­”æ¡ˆï¼Œä»»åŠ¡å®Œæˆï¼")
                        logger.info(f"æœ€ç»ˆç­”æ¡ˆä»»åŠ¡å®Œæˆ: {answer[:100]}...")

                        # æ ‡è®°ä»»åŠ¡å®Œæˆï¼Œæ¸…ç©ºpending_tasks
                        self.insight_doc.pending_tasks = []
                        completed_task = CompletedTask(
                            type=TaskType.NORMAL,
                            description=current_task,
                            status="æˆåŠŸ",
                            context=f"æœ€ç»ˆç­”æ¡ˆ: {answer[:100]}"
                        )
                        self.insight_doc.completed_tasks.append(completed_task)
                        break  # ç›´æ¥ç»“æŸå¾ªç¯

                    elif not tool_responses:
                        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä½†ReActè¿”å›äº†ç­”æ¡ˆ - ç›´æ¥æ ‡è®°ä»»åŠ¡å®Œæˆ
                        print("\nğŸ’¡ ReActç›´æ¥å›ç­”äº†é—®é¢˜ï¼ˆæœªè°ƒç”¨å·¥å…·ï¼‰")
                        logger.info("ReActç›´æ¥å›ç­”ï¼Œæœªè°ƒç”¨å·¥å…·")

                        if self.insight_doc.pending_tasks:
                            # ä¿å­˜ç­”æ¡ˆåˆ°å¤–å±‚å˜é‡ï¼ˆä»predictionå­—æ®µè·å–ï¼‰
                            answer = react_result.get("prediction", "")

                            # æ ‡è®°ä»»åŠ¡å®Œæˆ
                            self.insight_doc.pending_tasks.remove(current_task)
                            completed_task = CompletedTask(
                                type=TaskType.NORMAL,
                                description=current_task,
                                status="æˆåŠŸ",
                                context=f"ç›´æ¥å›ç­”: {answer[:200]}"
                            )
                            self.insight_doc.completed_tasks.append(completed_task)
                            print(f"âœ… ä»»åŠ¡å®Œæˆ: {current_task}")
                            logger.info(f"ä»»åŠ¡å·²å®Œæˆ: {current_task}")

                            # å¦‚æœæ˜¯æœ€ç»ˆå›ç­”ä»»åŠ¡ï¼Œç›´æ¥ç»“æŸå¾ªç¯
                            if is_final_answer_task:
                                print("\nâœ… è·å¾—æœ€ç»ˆç­”æ¡ˆï¼Œä»»åŠ¡å®Œæˆï¼")
                                logger.info(f"æœ€ç»ˆç­”æ¡ˆ: {answer[:100]}...")
                                break

                            # è°ƒç”¨Planning Agentæ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–ä»»åŠ¡
                            from src.agents.planning_agent import PlanningInput
                            planning_output = self.planning_agent.run(PlanningInput(
                                insight_doc=self.insight_doc,
                                new_memory_nodes=[],  # æ²¡æœ‰ç”Ÿæˆè®°å¿†èŠ‚ç‚¹
                                conflict_notification=None
                            ))

                            # æ›´æ–°insight_doc
                            self.insight_doc.pending_tasks = planning_output.pending_tasks
                            logger.info(f"Planning Agentæ›´æ–°: å¾…åŠä»»åŠ¡={len(self.insight_doc.pending_tasks)}")

                # 2.3 æ£€æŸ¥æ˜¯å¦æœ‰å¾…åŠä»»åŠ¡ï¼ˆå¦‚æœæ²¡æœ‰ï¼Œè¯´æ˜ä»»åŠ¡å®Œæˆï¼‰
                if not self.insight_doc or not self.insight_doc.pending_tasks:
                    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
                    logger.info("ä»»åŠ¡å®Œæˆï¼ˆæ— å¾…åŠä»»åŠ¡ï¼‰")
                    break

                # 2.4 å¦‚æœReActå·²ç»ç»™å‡ºç­”æ¡ˆä¸”æ— æ›´å¤šå¾…åŠä»»åŠ¡ï¼Œç»“æŸ
                if react_result.get("termination") == "answer" and not self.insight_doc.pending_tasks:
                    print("\nğŸ‰ ReAct Agentå·²ç»™å‡ºç­”æ¡ˆï¼Œä»»åŠ¡å®Œæˆï¼")
                    break

                # 2.5 å¢å¼ºä¸‹ä¸€è½®Promptï¼ˆåŸºäºæ–°çš„ä»»åŠ¡çŠ¶æ€ï¼‰
                print(f"\nğŸ”„ å‡†å¤‡ä¸‹ä¸€è½®æ‰§è¡Œ...")
                if self.insight_doc.pending_tasks:
                    print(f"ğŸ“‹ ä¸‹ä¸€æ­¥ä»»åŠ¡: {self.insight_doc.pending_tasks[0]}")
                enhanced_prompt = self.adapter.enhance_prompt(self.insight_doc)

            # 3. ç»Ÿè®¡ä¿¡æ¯
            final_insight_doc = self.insight_doc.to_dict() if self.insight_doc else None

            stats = {
                "iterations": iterations,
                "graph_nodes": self.query_graph.get_node_count(),
                "graph_edges": self.query_graph.get_edge_count(),
                "tree_entries": self.interaction_tree.get_total_entries(),
                "completed_tasks": len(self.insight_doc.completed_tasks) if self.insight_doc else 0,
                "pending_tasks": len(self.insight_doc.pending_tasks) if self.insight_doc else 0
            }

            logger.info("\n" + "=" * 60)
            logger.info("Task completed")
            logger.info(f"Stats: {stats}")
            logger.info("=" * 60)

            result = {
                "answer": answer or "Task finished but no explicit answer",
                "insight_doc": final_insight_doc,
                "stats": stats,
                "react_messages": last_react_result.get("messages", []) if last_react_result else []
            }

            return result

        except Exception as e:
            logger.error(f"Task execution failed: {str(e)}")
            import traceback
            traceback.print_exc()
            raise

        finally:
            if self.insight_doc is not None:
                self.adapter.cleanup_temp_storage()
                self.query_graph.clear()
                self.retrieval_module.mark_index_dirty()
                self.interaction_tree.clear()
                self.insight_doc = None

    def _initialize(self, user_input: str) -> str:
        """
        åˆå§‹åŒ–é˜¶æ®µ

        æµç¨‹ï¼š
        1. è§£æç”¨æˆ·è¾“å…¥
        2. å¤šæ¨¡æ€ä¸´æ—¶å­˜å‚¨
        3. åˆ†ç±»â†’ç»“æ„åŒ–â†’æ£€ç´¢â†’åˆ†æâ†’å»ºè¾¹
        4. è§„åˆ’ä¸‹ä¸€æ­¥
        5. å¢å¼ºPrompt

        Args:
            user_input: ç”¨æˆ·è¾“å…¥

        Returns:
            å¢å¼ºåçš„Prompt
        """
        logger.info("\n----- åˆå§‹åŒ–é˜¶æ®µ -----")

        # 1. è§£æç”¨æˆ·è¾“å…¥
        text_context, question = self._parse_user_input(user_input)
        doc_id = str(uuid.uuid4())

        logger.info(f"è§£æç»“æœ: ä¸Šä¸‹æ–‡é•¿åº¦={len(text_context)}, é—®é¢˜={question[:50]}...")

        # 2. åˆ¤æ–­æ˜¯å¦æœ‰æ–‡æœ¬ä¸Šä¸‹æ–‡
        if not text_context:
            logger.info("æ— æ–‡æœ¬ä¸Šä¸‹æ–‡ï¼Œç›´æ¥è¿›å…¥è§„åˆ’")
            # è·³åˆ°è§„åˆ’
            self.insight_doc = InsightDoc(
                doc_id=doc_id,
                task_goal=question,
                completed_tasks=[],
                pending_tasks=[]
            )
            planning_output = self.planning_agent.run(PlanningInput(
                insight_doc=self.insight_doc
            ))
            self.insight_doc = InsightDoc(
                doc_id=doc_id,
                task_goal=planning_output.task_goal,
                completed_tasks=planning_output.completed_tasks,
                pending_tasks=planning_output.pending_tasks
            )
            return self.adapter.enhance_prompt(self.insight_doc)

        # 3. åˆ†ç±»/èšç±»
        logger.info("æ‰§è¡Œåˆ†ç±»/èšç±»...")
        classification_output = self.classification_agent.run(ClassificationInput(
            context=text_context,
            task_goal=question
        ))
        logger.info(f"åˆ†ç±»ç»“æœ: should_cluster={classification_output.should_cluster}, "
                   f"clusters={len(classification_output.clusters)}")

        # 5-9. å¯¹æ¯ä¸ªclusterè¿›è¡Œå¤„ç†
        new_nodes = []
        conflicts = []

        for i, cluster in enumerate(classification_output.clusters):
            logger.info(f"\nå¤„ç†Cluster {i+1}/{len(classification_output.clusters)}: {cluster.context}")

            # 5. ç»“æ„åŒ–
            structure_output = self.structure_agent.run(StructureInput(
                content=cluster.content,  # âœ… ä¿®å¤ï¼šä½¿ç”¨ cluster.contentï¼ˆåŸå§‹æ–‡æœ¬ï¼‰
                context=cluster.context,
                keywords=cluster.keywords
            ))
            logger.debug(f"  ç»“æ„åŒ–å®Œæˆ: summaryé•¿åº¦={len(structure_output.summary)}")

            # 6. ç»„è£…èŠ‚ç‚¹
            node = self._create_node(
                summary=structure_output.summary,
                context=cluster.context,
                keywords=cluster.keywords  # ä½¿ç”¨clusterçš„keywordsï¼Œä¸æ˜¯structure_output
            )
            self.graph_ops.add_node(node)
            new_nodes.append(node)
            logger.debug(f"  æ–°èŠ‚ç‚¹å·²æ·»åŠ : {node.id[:8]}...")

            # âœ… ä¼˜åŒ–ï¼šæ ‡è®°ç´¢å¼•ä¸ºè„ï¼ˆç´¢å¼•ä¼šåœ¨ä¸‹æ¬¡æ£€ç´¢æ—¶è‡ªåŠ¨é‡å»ºï¼‰
            self.retrieval_module.mark_index_dirty()

            # 7. æ£€ç´¢ç›¸ä¼¼èŠ‚ç‚¹
            candidates = self.retrieval_module.hybrid_retrieval(
                query_embedding=node.embedding,
                query_keywords=node.keywords,
                graph=self.query_graph,
                exclude_ids={node.id}
            )
            logger.debug(f"  æ£€ç´¢åˆ° {len(candidates)} ä¸ªå€™é€‰èŠ‚ç‚¹")

            # 8. åˆ†æå…³ç³»
            if candidates:
                from src.agents.analysis_agent import AnalysisInput, NodeInfo
                analysis_input = AnalysisInput(
                    new_node=NodeInfo(
                        id=node.id,
                        summary=node.summary,
                        context=node.context,
                        keywords=node.keywords
                    ),
                    candidate_nodes=[
                        NodeInfo(
                            id=c.id,
                            summary=c.summary,
                            context=c.context,
                            keywords=c.keywords
                        )
                        for c in candidates
                    ]
                )
                analysis_output = self.analysis_agent.run(analysis_input)
                logger.debug(f"  åˆ†æå®Œæˆ: {len(analysis_output.relationships)} ä¸ªå…³ç³»")

                # å¤„ç†å…³ç³»
                for rel in analysis_output.relationships:
                    if rel.relationship == "conflict":
                        conflicts.append({
                            "node1": node.id,
                            "node2": rel.existing_node_id,
                            "description": rel.conflict_description
                        })
                        logger.info(f"    âš ï¸  æ£€æµ‹åˆ°å†²çª: {rel.conflict_description[:50]}...")
                    elif rel.relationship == "related":
                        self.graph_ops.add_edge(node.id, rel.existing_node_id)
                        logger.debug(f"    å»ºç«‹å…³è”è¾¹: {node.id[:8]}... <-> {rel.existing_node_id[:8]}...")

                        # æ›´æ–°ä¸Šä¸‹æ–‡
                        if rel.context_update_new:
                            self.context_updater.update_node_context(
                                node_id=node.id,
                                new_context=rel.context_update_new,
                                new_keywords=rel.keywords_update_new
                            )
                        if rel.context_update_existing:
                            self.context_updater.update_node_context(
                                node_id=rel.existing_node_id,
                                new_context=rel.context_update_existing,
                                new_keywords=rel.keywords_update_existing
                            )

            # 9. åˆ›å»ºInteraction Tree Entry
            entry = create_entry(
                text=cluster.content,  # âœ… ä¿®å¤ï¼šä¿å­˜å®Œæ•´å†…å®¹è€Œä¸æ˜¯ä¸€å¥è¯æ‘˜è¦
                metadata={"source": "user_input", "cluster_id": cluster.cluster_id}
            )
            self.interaction_tree.add_entry(node.id, entry)
            logger.debug(f"  Interaction Tree Entryå·²åˆ›å»º")

        # 10. è§„åˆ’
        logger.debug("æ‰§è¡Œä»»åŠ¡è§„åˆ’...")
        conflict_notification = None
        if conflicts:
            conflict_notification = ConflictNotification(
                conflicting_node_ids=[conflicts[0]["node1"], conflicts[0]["node2"]],
                conflict_description=conflicts[0]["description"]
            )
            logger.info(f"  âš ï¸  æ£€æµ‹åˆ°å†²çªï¼Œéœ€è¦äº¤å‰éªŒè¯")

        print(f"\nğŸ“… è°ƒç”¨ Planning Agent - è§„åˆ’ä¸‹ä¸€æ­¥ä»»åŠ¡...")
        planning_output = self.planning_agent.run(PlanningInput(
            insight_doc=InsightDoc(
                doc_id=doc_id,
                task_goal=question,
                completed_tasks=[],
                pending_tasks=[]
            ),
            new_memory_nodes=[
                {
                    "id": node.id,
                    "context": node.context,
                    "keywords": node.keywords,
                    "summary": node.summary
                }
                for node in new_nodes
            ],
            conflict_notification=conflict_notification
        ))
        print(f"   âœ… è§„åˆ’å®Œæˆ: {len(planning_output.pending_tasks)} ä¸ªå¾…åŠä»»åŠ¡")

        self.insight_doc = InsightDoc(
            doc_id=doc_id,
            task_goal=planning_output.task_goal,
            completed_tasks=planning_output.completed_tasks,
            pending_tasks=planning_output.pending_tasks
        )

        logger.info(f"è§„åˆ’å®Œæˆ: å¾…åŠä»»åŠ¡={len(self.insight_doc.pending_tasks)}")

        # 11. å¢å¼ºPrompt
        return self.adapter.enhance_prompt(self.insight_doc)

    def _create_node(self, summary: str, context: str, keywords: List[str]) -> QueryGraphNode:
        """
        åˆ›å»ºQuery GraphèŠ‚ç‚¹

        Args:
            summary: æ‘˜è¦
            context: ä¸Šä¸‹æ–‡
            keywords: å…³é”®è¯åˆ—è¡¨

        Returns:
            QueryGraphNodeå®ä¾‹
        """
        node_id = str(uuid.uuid4())
        timestamp = time.time()
        text = f"{summary} {context} {' '.join(keywords)}"
        embedding = self.embedding_module.compute_embedding(text)

        return QueryGraphNode(
            id=node_id,
            summary=summary,
            context=context,
            keywords=keywords,
            embedding=embedding,
            timestamp=timestamp,
            links=[]  # âœ… ä¿®å¤ï¼šåº”è¯¥æ˜¯listè€Œä¸æ˜¯set
        )

    def _parse_user_input(self, user_input: str) -> Tuple[str, str]:
        """
        è§£æç”¨æˆ·è¾“å…¥

        æ”¯æŒæ ¼å¼ï¼š
        1. çº¯é—®é¢˜
        2. "ä¸Šä¸‹æ–‡ï¼š...\né—®é¢˜ï¼š..."
        3. "Context:...\nQuestion:..."

        Args:
            user_input: ç”¨æˆ·è¾“å…¥

        Returns:
            (text_context, question)
        """
        lines = user_input.split('\n')
        text_context = ""
        question = ""

        for line in lines:
            line = line.strip()
            if not line:
                continue

            if line.startswith("ä¸Šä¸‹æ–‡ï¼š") or line.startswith("Context:"):
                separator = "ï¼š" if "ï¼š" in line else ":"
                text_context = line.split(separator, 1)[1].strip()
            elif line.startswith("é—®é¢˜ï¼š") or line.startswith("Question:"):
                separator = "ï¼š" if "ï¼š" in line else ":"
                question = line.split(separator, 1)[1].strip()
            elif not question and not text_context:
                # ç¬¬ä¸€è¡Œä¸”æ²¡æœ‰å‰ç¼€ï¼Œå½“ä½œé—®é¢˜
                question = line

        # å¦‚æœæ²¡æœ‰æ˜ç¡®é—®é¢˜ï¼Œæ•´ä¸ªè¾“å…¥ä½œä¸ºé—®é¢˜
        if not question:
            question = user_input

        return text_context, question

    def _extract_tool_responses(self, messages: List[Dict[str, str]]) -> List[str]:
        """
        ä»ReActæ¶ˆæ¯å†å²ä¸­æå–å·¥å…·å“åº”å†…å®¹ï¼ˆä»…å·¥å…·è¾“å‡ºï¼‰

        Args:
            messages: ReActæ¶ˆæ¯å†å²

        Returns:
            å·¥å…·å“åº”æ–‡æœ¬åˆ—è¡¨
        """
        tool_responses = []

        for message in messages:
            if message.get("role") == "user" and "content" in message:
                content = message["content"]

                # æå–<tool_response>æ ‡ç­¾å†…å®¹
                if '<tool_response>' in content and '</tool_response>' in content:
                    try:
                        response_text = content.split('<tool_response>')[1].split('</tool_response>')[0]
                        response_text = response_text.strip()

                        if response_text and response_text not in tool_responses:
                            tool_responses.append(response_text)
                            logger.debug(f"æå–å·¥å…·å“åº”: {response_text[:100]}...")
                    except Exception as e:
                        logger.warning(f"è§£æå·¥å…·å“åº”å¤±è´¥: {str(e)}")

        return tool_responses

    def _extract_full_context(self, messages: List[Dict[str, str]]) -> str:
        """
        ä»ReActæ¶ˆæ¯å†å²ä¸­æå–å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬æ€è€ƒã€å·¥å…·è°ƒç”¨å’Œå“åº”ï¼‰

        è¿™ä¸ªæ–¹æ³•æå–ï¼š
        1. ReAct Agentçš„æ€è€ƒè¿‡ç¨‹ï¼ˆ<think>æ ‡ç­¾ï¼‰
        2. å·¥å…·è°ƒç”¨å’Œå‚æ•°
        3. å·¥å…·å“åº”ç»“æœ

        Args:
            messages: ReActæ¶ˆæ¯å†å²

        Returns:
            å®Œæ•´çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        context_parts = []

        for message in messages:
            role = message.get("role", "")
            content = message.get("content", "")

            if role == "assistant":
                # æå–æ€è€ƒè¿‡ç¨‹
                if '<think>' in content and '</think>' in content:
                    try:
                        think_text = content.split('<think>')[1].split('</think>')[0].strip()
                        if think_text:
                            context_parts.append(f"ã€åˆ†æè¿‡ç¨‹ã€‘\n{think_text}")
                    except Exception as e:
                        logger.warning(f"è§£ææ€è€ƒå†…å®¹å¤±è´¥: {str(e)}")

                # âœ… ä¿®å¤ï¼šæå–å·¥å…·è°ƒç”¨å‚æ•°ï¼ˆåŒ…å«é‡è¦è¯­ä¹‰ä¿¡æ¯ï¼‰
                if '<tool_call>' in content and '</tool_call>' in content:
                    try:
                        tool_call_text = content.split('<tool_call>')[1].split('</tool_call>')[0].strip()
                        if tool_call_text:
                            # è§£æJSONå¹¶æ ¼å¼åŒ–
                            import json
                            tool_call_json = json.loads(tool_call_text)
                            tool_name = tool_call_json.get('name', '')
                            tool_args = tool_call_json.get('arguments', {})
                            context_parts.append(f"ã€å·¥å…·è°ƒç”¨ã€‘\nå·¥å…·: {tool_name}\nå‚æ•°: {json.dumps(tool_args, ensure_ascii=False)}")
                    except Exception as e:
                        logger.warning(f"è§£æå·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}")

            elif role == "user":
                # æå–å·¥å…·å“åº”
                if '<tool_response>' in content and '</tool_response>' in content:
                    try:
                        response_text = content.split('<tool_response>')[1].split('</tool_response>')[0].strip()
                        if response_text:
                            context_parts.append(f"ã€å·¥å…·è¾“å‡ºã€‘\n{response_text}")
                    except Exception as e:
                        logger.warning(f"è§£æå·¥å…·å“åº”å¤±è´¥: {str(e)}")

        full_context = "\n\n".join(context_parts)
        logger.debug(f"æå–å®Œæ•´ä¸Šä¸‹æ–‡: {len(context_parts)} ä¸ªéƒ¨åˆ†ï¼Œæ€»é•¿åº¦ {len(full_context)} å­—ç¬¦")

        return full_context

    def _should_terminate(self) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ç»ˆæ­¢

        Returns:
            æ˜¯å¦åº”è¯¥ç»ˆæ­¢ä»»åŠ¡
        """
        if not self.insight_doc:
            return False

        # å¦‚æœæ²¡æœ‰å¾…åŠä»»åŠ¡ä¸”æ‰€æœ‰å·²å®Œæˆä»»åŠ¡éƒ½æˆåŠŸï¼Œåˆ™ç»ˆæ­¢
        no_pending = len(self.insight_doc.pending_tasks) == 0
        all_success = all(
            task.status == "æˆåŠŸ"
            for task in self.insight_doc.completed_tasks
        ) if self.insight_doc.completed_tasks else True

        return no_pending and all_success

    def export_memory(self, filepath: str):
        """
        å¯¼å‡ºè®°å¿†åˆ°JSONæ–‡ä»¶

        Args:
            filepath: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        import json

        memory_data = {
            "insight_doc": self.insight_doc.to_dict() if self.insight_doc else None,
            "query_graph": self.query_graph.to_dict(),
            "interaction_tree": self.interaction_tree.to_dict()
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(memory_data, f, ensure_ascii=False, indent=2)

        logger.info(f"è®°å¿†å·²å¯¼å‡ºåˆ°: {filepath}")

    def load_memory(self, filepath: str):
        """
        ä»JSONæ–‡ä»¶åŠ è½½è®°å¿†

        Args:
            filepath: è¾“å…¥æ–‡ä»¶è·¯å¾„
        """
        import json

        with open(filepath, 'r', encoding='utf-8') as f:
            memory_data = json.load(f)

        if memory_data.get("insight_doc"):
            self.insight_doc = InsightDoc.from_dict(memory_data["insight_doc"])

        self.query_graph = QueryGraph.from_dict(memory_data["query_graph"])
        self.interaction_tree = InteractionTree.from_dict(memory_data["interaction_tree"])

        logger.info(f"è®°å¿†å·²ä»æ–‡ä»¶åŠ è½½: {filepath}")

    def __repr__(self) -> str:
        """è¿”å›Memory Bankæ‘˜è¦"""
        return (
            f"MemoryBank("
            f"nodes={self.query_graph.get_node_count()}, "
            f"edges={self.query_graph.get_edge_count()}, "
            f"entries={self.interaction_tree.get_total_entries()})"
        )
