"""
Agentic Memory Bank æ ¸å¿ƒç±»

æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œæä¾›å®Œæ•´çš„è®°å¿†ç®¡ç†åŠŸèƒ½ã€‚
"""

import logging
import uuid
import time
from typing import Dict, Any, List, Optional, Tuple

from src.storage.insight_doc import InsightDoc, CompletedTask, TaskType
from src.storage.query_graph import QueryGraph, QueryGraphNode
from src.storage.interaction_tree import InteractionTree
from src.modules.embedding import EmbeddingModule
from src.modules.retrieval import RetrievalModule
from src.modules.graph_ops import GraphOperations
from src.agents.classification_agent import ClassificationAgent, ClassificationInput
from src.agents.structure_agent import StructureAgent, StructureInput
from src.agents.analysis_agent import AnalysisAgent, AnalysisInput
from src.agents.integration_agent import IntegrationAgent, IntegrationInput, NodeWithNeighbors
from src.agents.planning_agent import PlanningAgent, PlanningInput, ConflictNotification
from src.interface.adapter import MemoryBankAdapter
from src.tools.deep_retrieval_tool import DeepRetrievalTool
from src.tools.search_tool import SearchTool
from src.tools.visit_tool import VisitTool
from src.tools.react_agent import MultiTurnReactAgent
from src.utils.llm_client import LLMClient
from src.utils.file_utils import FileUtils
from src.config import Config
from src.prompts.agent_prompts import REACT_SYSTEM_PROMPT

logger = logging.getLogger(__name__)


class MemoryBank:
    """Agentic Memory Bankä¸»ç±»"""

    def __init__(self, config: Config = None):
        """
        åˆå§‹åŒ–Memory Bank

        Args:
            config: é…ç½®å¯¹è±¡ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
        """
        logger.info("Initializing Agentic Memory Bank...")

        # åˆå§‹åŒ–é…ç½®
        self.config = config or Config()

        # åˆå§‹åŒ–å­˜å‚¨å±‚
        self.query_graph = QueryGraph()
        self.interaction_tree = InteractionTree()
        self.insight_doc = None  # æ¯æ¬¡ä»»åŠ¡å•ç‹¬åˆ›å»º

        # åˆå§‹åŒ–å·¥å…·
        self.llm_client = LLMClient.from_config(self.config)
        self.file_utils = FileUtils(
            temp_dir=self.config.TEMP_DIR,
            storage_dir=self.config.STORAGE_DIR
        )

        # åˆå§‹åŒ–ç¡¬ç¼–ç æ¨¡å—
        self.embedding_module = EmbeddingModule.from_config(self.config)
        self.retrieval_module = RetrievalModule(
            alpha=self.config.RETRIEVAL_ALPHA,
            k=self.config.RETRIEVAL_K
        )
        self.graph_ops = GraphOperations(self.query_graph)

        # åˆå§‹åŒ–Agent
        self.classification_agent = ClassificationAgent.from_config(
            self.llm_client, self.config
        )
        self.structure_agent = StructureAgent.from_config(self.llm_client, self.config)
        self.analysis_agent = AnalysisAgent.from_config(self.llm_client, self.config)
        self.integration_agent = IntegrationAgent.from_config(self.llm_client, self.config)
        self.planning_agent = PlanningAgent.from_config(self.llm_client, self.config)

        # åˆå§‹åŒ–Interfaceå±‚
        self.deep_retrieval_tool = DeepRetrievalTool(self.interaction_tree, self.file_utils)

        # æœç´¢å·¥å…·ï¼šå¦‚æœé…ç½®äº†Serper API keyï¼Œä½¿ç”¨çœŸå®æœç´¢
        search_api_key = self.config.SERPER_API_KEY
        if not search_api_key or search_api_key == "your-serper-api-key-here":
            raise ValueError(
                "æœªé…ç½®Serper API keyã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®SERPER_API_KEYã€‚\n"
                "æ³¨å†Œåœ°å€ï¼šhttps://serper.dev/"
            )

        self.search_tool = SearchTool(search_api_key=search_api_key)

        # Visitå·¥å…·ï¼šä½¿ç”¨Jina Reader APIï¼ˆå¿…éœ€ï¼‰
        jina_api_key = self.config.JINA_API_KEY
        self.visit_tool = VisitTool(
            llm_client=self.llm_client,
            jina_api_key=jina_api_key,
            temperature=self.config.VISIT_EXTRACTION_TEMPERATURE,
            top_p=self.config.VISIT_EXTRACTION_TOP_P
        )

        # åˆå§‹åŒ–Adapter
        self.adapter = MemoryBankAdapter(self, self.retrieval_module, self.file_utils)

        # åˆå§‹åŒ–ReAct Agent
        tools = {
            "deep_retrieval": self.deep_retrieval_tool,
            "search": self.search_tool,
            "visit": self.visit_tool
        }
        self.react_agent = MultiTurnReactAgent(
            llm_client=self.llm_client,
            tools=tools,
            system_message=REACT_SYSTEM_PROMPT,
            max_iterations=self.config.MAX_LLM_CALL_PER_RUN,
            max_context_tokens=self.config.MAX_CONTEXT_TOKENS,
            temperature=self.config.REACT_AGENT_TEMPERATURE,
            top_p=self.config.REACT_AGENT_TOP_P
        )

        logger.info("Agentic Memory Bank initialized successfully")

    def run(self, user_input: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•æ¬¡ä»»åŠ¡

        Args:
            user_input: ç”¨æˆ·è¾“å…¥ï¼ˆå¯èƒ½åŒ…å«ä¸Šä¸‹æ–‡+é—®é¢˜ï¼‰

        Returns:
            ä»»åŠ¡ç»“æœï¼š{
                "answer": str,
                "insight_doc": dict,
                "stats": dict
            }
        """
        logger.info("=" * 60)
        logger.info(f"Starting new task: {user_input[:300]}{'...' if len(user_input) > 300 else ''}")
        logger.info("=" * 60)

        try:
            # 1. åˆå§‹åŒ–é˜¶æ®µ
            print("\n" + "=" * 80)
            print("  Memory Bank Initialized")
            print("=" * 80)
            enhanced_prompt = self._initialize(user_input)
            iterations = 0

            # æ˜¾ç¤ºä»»åŠ¡ç›®æ ‡å’Œåˆå§‹çŠ¶æ€
            if self.insight_doc:
                print(f"Task: {self.insight_doc.task_goal}")
                print(f"Current Subtask: {self.insight_doc.current_task if self.insight_doc.current_task else '(none)'}")
                print("=" * 80)

            # 2. æ‰§è¡Œå¾ªç¯
            answer = None
            last_react_result = None  # ä¿å­˜æœ€åä¸€æ¬¡ReActç»“æœ
            max_iterations = self.config.MAX_LLM_CALL_PER_RUN
            while not self._should_terminate() and iterations < max_iterations:
                iterations += 1
                print(f"\n{'=' * 80}")
                print(f"  Iteration {iterations}")
                print("=" * 80)

                # æ˜¾ç¤ºå½“å‰ä»»åŠ¡çŠ¶æ€ï¼ˆç®€åŒ–ï¼‰
                if self.insight_doc and self.insight_doc.current_task:
                    print(f"Current: {self.insight_doc.current_task}")
                    print(f"Completed: {len(self.insight_doc.completed_tasks)} | Memory nodes: {self.query_graph.get_node_count()}")

                # 2.1 ReActæ‰§è¡Œ
                react_result = self.react_agent.run(enhanced_prompt)
                last_react_result = react_result  # ä¿å­˜ç»“æœ
                answer = react_result.get("prediction", "")

                # 2.2 ä¸Šä¸‹æ–‡æ‹¦æˆªï¼šæå–æœç´¢ç»“æœå¹¶è½¬åŒ–ä¸ºè®°å¿†
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆå›ç­”ä»»åŠ¡
                current_task = self.insight_doc.current_task if self.insight_doc else ""
                is_final_answer_task = "æ ¹æ®ç°æœ‰ç›¸å…³è®°å¿†ç›´æ¥å›ç­”é—®é¢˜" in current_task or "æ ¹æ®ç°æœ‰è®°å¿†å›ç­”é—®é¢˜" in current_task

                if self.insight_doc and self.insight_doc.current_task:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼ˆé€šè¿‡æ£€æŸ¥æ¶ˆæ¯å†å²ï¼‰
                    messages = react_result.get("messages", [])
                    has_tool_calls = any(
                        msg.get("role") == "assistant" and "<tool_call>" in msg.get("content", "")
                        for msg in messages
                    )

                    tool_responses = self._extract_tool_responses(messages)

                    if has_tool_calls and not is_final_answer_task:
                        # æœ‰å·¥å…·è°ƒç”¨ï¼Œä¸”ä¸æ˜¯æœ€ç»ˆå›ç­”ä»»åŠ¡ - è¿›å…¥è®°å¿†å¤„ç†æµç¨‹
                        # (No console output - details logged to file)

                        # æå–å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬æ€è€ƒè¿‡ç¨‹ã€å·¥å…·è°ƒç”¨å’Œå·¥å…·å“åº”ï¼‰
                        # Classification Agent éœ€è¦å®Œæ•´ä¸Šä¸‹æ–‡æ¥å‡†ç¡®åˆ†ç±»å’Œç†è§£æ¨ç†è¿‡ç¨‹
                        full_context = self._extract_full_context(messages)

                        # è°ƒç”¨ä¸Šä¸‹æ–‡æ‹¦æˆªæœºåˆ¶
                        try:
                            # åˆ¤æ–­ä»»åŠ¡ç±»å‹ï¼ˆå‚è€ƒ REQUIREMENTS_FINAL.md ç¬¬4.2èŠ‚ï¼‰
                            has_conflict = self.adapter.has_pending_conflicts()
                            if has_conflict:
                                task_type = "CROSS_VALIDATE"
                            else:
                                task_type = "NORMAL"

                            # intercept_context å†…éƒ¨ä¼šè°ƒç”¨ Planning Agent æ›´æ–° insight_doc
                            # åŒ…æ‹¬ completed_tasks å’Œ pending_tasks
                            self.adapter.intercept_context(full_context, task_type, self.insight_doc)
                            # (Memory processing complete - logged to file)

                        except Exception as e:
                            print(f"Error: {str(e)}")
                            logger.error(f"Context interception failed: {str(e)}")
                            import traceback
                            traceback.print_exc()

                    elif is_final_answer_task and react_result.get("termination") == "answer":
                        # æœ€ç»ˆå›ç­”ä»»åŠ¡ä¸”æœ‰ç­”æ¡ˆ - ä½†ä¸èƒ½ç›´æ¥è®¤ä¸ºå®Œæˆï¼Œéœ€è¦Planning AgentéªŒè¯
                        answer = react_result.get("prediction", "")

                        # è°ƒç”¨Planning AgentéªŒè¯ç­”æ¡ˆ
                        from src.agents.planning_agent import PlanningInput
                        planning_output = self.planning_agent.run(PlanningInput(
                            insight_doc=self.insight_doc,
                            new_memory_nodes=[
                                {
                                    "id": "final_answer",
                                    "context": "Final answer candidate",
                                    "keywords": ["answer", "final"],
                                    "summary": answer
                                }
                            ],
                            conflict_notification=None
                        ))

                        # æ›´æ–°insight_doc
                        self.insight_doc.task_goal = planning_output.task_goal
                        self.insight_doc.completed_tasks = planning_output.completed_tasks
                        self.insight_doc.current_task = planning_output.current_task

                        # å¦‚æœPlanning Agentåˆ¤æ–­æ²¡æœ‰åç»­ä»»åŠ¡äº†ï¼Œæ‰çœŸæ­£ç»“æŸ
                        if not self.insight_doc.current_task:
                            print("\n[DONE] Task complete - Final answer obtained and verified")
                            break

                    elif not tool_responses:
                        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä½†ReActè¿”å›äº†ç­”æ¡ˆ - ç›´æ¥æ ‡è®°ä»»åŠ¡å®Œæˆ
                        # (ReAct provided direct answer without tools)

                        if self.insight_doc.current_task:
                            # ä¿å­˜ç­”æ¡ˆåˆ°å¤–å±‚å˜é‡ï¼ˆä»predictionå­—æ®µè·å–ï¼‰
                            answer = react_result.get("prediction", "")

                            # æ ‡è®°ä»»åŠ¡å®Œæˆ
                            self.insight_doc.current_task = ""
                            completed_task = CompletedTask(
                                type=TaskType.NORMAL,
                                description=current_task,
                                status="Success",
                                context=f"ç›´æ¥å›ç­”: {answer[:200]}"
                            )
                            self.insight_doc.completed_tasks.append(completed_task)

                            # å¦‚æœæ˜¯æœ€ç»ˆå›ç­”ä»»åŠ¡ï¼Œç›´æ¥ç»“æŸå¾ªç¯
                            if is_final_answer_task:
                                print("\n[DONE] Task complete - Final answer obtained")
                                break

                            # è°ƒç”¨Planning Agentæ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–ä»»åŠ¡
                            from src.agents.planning_agent import PlanningInput
                            planning_output = self.planning_agent.run(PlanningInput(
                                insight_doc=self.insight_doc,
                                new_memory_nodes=[],  # æ²¡æœ‰ç”Ÿæˆè®°å¿†èŠ‚ç‚¹
                                conflict_notification=None
                            ))

                            # æ›´æ–°insight_doc
                            self.insight_doc.current_task = planning_output.current_task

                # 2.3 æ£€æŸ¥æ˜¯å¦æœ‰å¾…åŠä»»åŠ¡ï¼ˆå¦‚æœæ²¡æœ‰ï¼Œè¯´æ˜ä»»åŠ¡å®Œæˆï¼‰
                if not self.insight_doc or not self.insight_doc.current_task:
                    print("\n[DONE] All tasks complete")
                    break

                # 2.4 å¦‚æœReActå·²ç»ç»™å‡ºç­”æ¡ˆä¸”æ— æ›´å¤šå¾…åŠä»»åŠ¡ï¼Œç»“æŸ
                if react_result.get("termination") == "answer" and not self.insight_doc.current_task:
                    print("\n[DONE] Task complete")
                    break

                # 2.5 å¢å¼ºä¸‹ä¸€è½®Promptï¼ˆåŸºäºæ–°çš„ä»»åŠ¡çŠ¶æ€ï¼‰
                if self.insight_doc.current_task:
                    print(f"\nNext: {self.insight_doc.current_task}")
                enhanced_prompt = self.adapter.enhance_prompt(self.insight_doc)

            # 3. ç»Ÿè®¡ä¿¡æ¯
            final_insight_doc = self.insight_doc.to_dict() if self.insight_doc else None

            stats = {
                "iterations": iterations,
                "graph_nodes": self.query_graph.get_node_count(),
                "graph_edges": self.query_graph.get_edge_count(),
                "tree_entries": self.interaction_tree.get_total_entries(),
                "completed_tasks": len(self.insight_doc.completed_tasks) if self.insight_doc else 0,
                "current_task": self.insight_doc.current_task if self.insight_doc else ""
            }

            logger.info("\n" + "=" * 60)
            logger.info("Task completed")
            logger.info(f"Stats: {stats}")
            logger.info("=" * 60)

            # æ˜¾ç¤ºå®Œæ•´Memory Bankè®°å¿†
            self._display_complete_memory()

            result = {
                "answer": answer or "Task finished but no explicit answer",
                "insight_doc": final_insight_doc,
                "stats": stats,
                "react_messages": last_react_result.get("messages", []) if last_react_result else []
            }

            return result

        except Exception as e:
            logger.error(f"Task execution failed: {str(e)}")
            import traceback
            traceback.print_exc()
            raise

        finally:
            if self.insight_doc is not None:
                self.adapter.cleanup_temp_storage()
                self.query_graph.clear()
                self.retrieval_module.mark_index_dirty()
                self.interaction_tree.clear()
                self.insight_doc = None

    def _initialize(self, user_input: str) -> str:
        """
        åˆå§‹åŒ–é˜¶æ®µ

        æµç¨‹ï¼š
        1. è§£æç”¨æˆ·è¾“å…¥
        2. å¤šæ¨¡æ€ä¸´æ—¶å­˜å‚¨
        3. åˆ†ç±»â†’ç»“æ„åŒ–â†’æ£€ç´¢â†’åˆ†æâ†’å»ºè¾¹
        4. è§„åˆ’ä¸‹ä¸€æ­¥
        5. å¢å¼ºPrompt

        Args:
            user_input: ç”¨æˆ·è¾“å…¥

        Returns:
            å¢å¼ºåçš„Prompt
        """
        # 1. è§£æç”¨æˆ·è¾“å…¥
        text_context, question = self._parse_user_input(user_input)
        doc_id = str(uuid.uuid4())

        # 2. åˆ¤æ–­æ˜¯å¦æœ‰æ–‡æœ¬ä¸Šä¸‹æ–‡
        if not text_context:
            # è·³åˆ°è§„åˆ’
            self.insight_doc = InsightDoc(
                doc_id=doc_id,
                task_goal=question,
                completed_tasks=[],
                current_task=""
            )
            planning_output = self.planning_agent.run(PlanningInput(
                insight_doc=self.insight_doc
            ))
            self.insight_doc = InsightDoc(
                doc_id=doc_id,
                task_goal=planning_output.task_goal,
                completed_tasks=planning_output.completed_tasks,
                current_task=planning_output.current_task
            )
            return self.adapter.enhance_prompt(self.insight_doc)

        # 3. åˆ†ç±»/èšç±»
        classification_output = self.classification_agent.run(ClassificationInput(
            context=text_context,
            task_goal=question
        ))

        # 5-9. å¯¹æ¯ä¸ªclusterè¿›è¡Œå¤„ç†
        new_nodes = []
        conflicts = []

        for i, cluster in enumerate(classification_output.clusters):

            # 5. ç»“æ„åŒ–
            structure_output = self.structure_agent.run(StructureInput(
                content=cluster.content,  # âœ… ä¿®å¤ï¼šä½¿ç”¨ cluster.contentï¼ˆåŸå§‹æ–‡æœ¬ï¼‰
                context=cluster.context,
                keywords=cluster.keywords,
                current_task=question  # ä½¿ç”¨ç”¨æˆ·é—®é¢˜ä½œä¸ºå½“å‰ä»»åŠ¡å‚è€ƒ
            ))

            # 6. ç»„è£…èŠ‚ç‚¹
            node = self._create_node(
                summary=structure_output.summary,
                context=cluster.context,
                keywords=cluster.keywords  # ä½¿ç”¨clusterçš„keywordsï¼Œä¸æ˜¯structure_output
            )
            self.graph_ops.add_node(node)
            new_nodes.append(node)

            # âœ… ä¼˜åŒ–ï¼šæ ‡è®°ç´¢å¼•ä¸ºè„ï¼ˆç´¢å¼•ä¼šåœ¨ä¸‹æ¬¡æ£€ç´¢æ—¶è‡ªåŠ¨é‡å»ºï¼‰
            self.retrieval_module.mark_index_dirty()

            # 7. æ£€ç´¢ç›¸ä¼¼èŠ‚ç‚¹
            candidates = self.retrieval_module.hybrid_retrieval(
                query_embedding=node.embedding,
                query_keywords=node.keywords,
                graph=self.query_graph,
                exclude_ids={node.id}
            )

            # 8. åˆ†æå…³ç³»
            if candidates:
                from src.agents.analysis_agent import AnalysisInput, NodeInfo
                analysis_input = AnalysisInput(
                    new_node=NodeInfo(
                        id=node.id,
                        summary=node.summary,
                        context=node.context,
                        keywords=node.keywords,
                        merge_description=node.merge_description
                    ),
                    candidate_nodes=[
                        NodeInfo(
                            id=c.id,
                            summary=c.summary,
                            context=c.context,
                            keywords=c.keywords,
                            merge_description=c.merge_description
                        )
                        for c in candidates
                    ]
                )
                analysis_output = self.analysis_agent.run(analysis_input)

                # å¤„ç†å…³ç³»
                for rel in analysis_output.relationships:
                    if rel.relationship == "conflict":
                        conflicts.append({
                            "node1": node.id,
                            "node2": rel.existing_node_id,
                            "description": rel.conflict_description
                        })
                        logger.info(f"    âš ï¸  Conflict detected: {rel.conflict_description[:150]}{'...' if len(rel.conflict_description or '') > 150 else ''}")
                    elif rel.relationship == "related":
                        self.graph_ops.add_edge(node.id, rel.existing_node_id)

            # 9. åˆ›å»ºInteraction Tree Entryï¼ˆä¿å­˜å®Œæ•´å†…å®¹ï¼‰
            self.interaction_tree.add_entry(node.id, cluster.content)

        # 10. è§„åˆ’
        conflict_notification = None
        if conflicts:
            conflict_notification = ConflictNotification(
                conflicting_node_ids=[conflicts[0]["node1"], conflicts[0]["node2"]],
                conflict_description=conflicts[0]["description"]
            )
            # âœ… ä¿®å¤ï¼šå°†å†²çªæ·»åŠ åˆ°adapteré˜Ÿåˆ—ï¼ˆä¸_handle_normal_taskä¿æŒä¸€è‡´ï¼‰
            # ç¡®ä¿æ‰§è¡Œå¾ªç¯ä¸­has_pending_conflicts()èƒ½æ­£ç¡®è¯†åˆ«å†²çªçŠ¶æ€
            for conflict in conflicts:
                pair = [conflict["node1"], conflict["node2"]]
                if pair not in self.adapter._pending_conflicts:
                    self.adapter._pending_conflicts.append(pair)
            logger.info(f"  âš ï¸  Conflict detected, cross-validation needed")

        # âœ… ä¿®å¤ï¼šåˆå§‹åŒ–insight_docï¼ˆåœ¨è°ƒç”¨Planning Agentä¹‹å‰ï¼‰
        # ç¡®ä¿Planning Agentæ¥æ”¶åˆ°æœ‰æ•ˆçš„InsightDocå¯¹è±¡ï¼Œè€Œä¸æ˜¯None
        self.insight_doc = InsightDoc(
            doc_id=doc_id,
            task_goal=question,
            completed_tasks=[],
            current_task=""
        )

        print(f"\n[Planning] Calling Planning Agent - planning next task...")
        # âœ… ä¿®å¤ï¼šä¼ å…¥å½“å‰çš„ insight_docï¼ˆåŒ…å«å·²å®Œæˆçš„ä»»åŠ¡ï¼‰ï¼Œè€Œä¸æ˜¯ç©ºçš„ InsightDoc
        planning_output = self.planning_agent.run(PlanningInput(
            insight_doc=self.insight_doc,
            new_memory_nodes=[
                {
                    "id": node.id,
                    "context": node.context,
                    "keywords": node.keywords,
                    "summary": node.summary
                }
                for node in new_nodes
            ],
            conflict_notification=conflict_notification
        ))
        print(f"   [OK] Planning complete: current task={'yes' if planning_output.current_task else 'no'}")

        # âœ… æ›´æ–°insight_docï¼ˆä½¿ç”¨Planning Agentçš„è¾“å‡ºï¼‰
        self.insight_doc.task_goal = planning_output.task_goal
        self.insight_doc.completed_tasks = planning_output.completed_tasks
        self.insight_doc.current_task = planning_output.current_task

        # 11. å¢å¼ºPrompt
        return self.adapter.enhance_prompt(self.insight_doc)

    def _create_node(self, summary: str, context: str, keywords: List[str]) -> QueryGraphNode:
        """
        åˆ›å»ºQuery GraphèŠ‚ç‚¹

        Args:
            summary: æ‘˜è¦
            context: ä¸Šä¸‹æ–‡
            keywords: å…³é”®è¯åˆ—è¡¨

        Returns:
            QueryGraphNodeå®ä¾‹
        """
        node_id = str(uuid.uuid4())
        timestamp = time.time()
        text = f"{summary} {context} {' '.join(keywords)}"
        embedding = self.embedding_module.compute_embedding(text)

        return QueryGraphNode(
            id=node_id,
            summary=summary,
            context=context,
            keywords=keywords,
            embedding=embedding,
            timestamp=timestamp,
            links=[]  # âœ… ä¿®å¤ï¼šåº”è¯¥æ˜¯listè€Œä¸æ˜¯set
        )

    def _parse_user_input(self, user_input: str) -> Tuple[str, str]:
        """
        è§£æç”¨æˆ·è¾“å…¥

        æ”¯æŒæ ¼å¼ï¼š
        1. çº¯é—®é¢˜
        2. "ä¸Šä¸‹æ–‡ï¼š...\né—®é¢˜ï¼š..."
        3. "Context:...\nQuestion:..."

        Args:
            user_input: ç”¨æˆ·è¾“å…¥

        Returns:
            (text_context, question)
        """
        lines = user_input.split('\n')
        text_context = ""
        question = ""

        for line in lines:
            line = line.strip()
            if not line:
                continue

            if line.startswith("ä¸Šä¸‹æ–‡ï¼š") or line.startswith("Context:"):
                separator = "ï¼š" if "ï¼š" in line else ":"
                text_context = line.split(separator, 1)[1].strip()
            elif line.startswith("é—®é¢˜ï¼š") or line.startswith("Question:"):
                separator = "ï¼š" if "ï¼š" in line else ":"
                question = line.split(separator, 1)[1].strip()
            elif not question and not text_context:
                # ç¬¬ä¸€è¡Œä¸”æ²¡æœ‰å‰ç¼€ï¼Œå½“ä½œé—®é¢˜
                question = line

        # å¦‚æœæ²¡æœ‰æ˜ç¡®é—®é¢˜ï¼Œæ•´ä¸ªè¾“å…¥ä½œä¸ºé—®é¢˜
        if not question:
            question = user_input

        return text_context, question

    def _extract_tool_responses(self, messages: List[Dict[str, str]]) -> List[str]:
        """
        ä»ReActæ¶ˆæ¯å†å²ä¸­æå–å·¥å…·å“åº”å†…å®¹ï¼ˆä»…å·¥å…·è¾“å‡ºï¼‰

        Args:
            messages: ReActæ¶ˆæ¯å†å²

        Returns:
            å·¥å…·å“åº”æ–‡æœ¬åˆ—è¡¨
        """
        tool_responses = []

        for message in messages:
            if message.get("role") == "user" and "content" in message:
                content = message["content"]

                # æå–<tool_response>æ ‡ç­¾å†…å®¹
                if '<tool_response>' in content and '</tool_response>' in content:
                    try:
                        response_text = content.split('<tool_response>')[1].split('</tool_response>')[0]
                        response_text = response_text.strip()

                        if response_text and response_text not in tool_responses:
                            tool_responses.append(response_text)
                    except Exception as e:
                        logger.warning(f"Failed to parse tool response: {str(e)}")

        return tool_responses

    def _extract_full_context(self, messages: List[Dict[str, str]]) -> str:
        """
        ä»ReActæ¶ˆæ¯å†å²ä¸­æå–å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬æ€è€ƒã€å·¥å…·è°ƒç”¨ã€å“åº”å’Œç­”æ¡ˆï¼‰

        è¿™ä¸ªæ–¹æ³•æå–ï¼š
        1. ReAct Agentçš„å®Œæ•´å“åº”ï¼ˆä¿ç•™<think>ã€<tool_call>ã€<answer>ç­‰æ‰€æœ‰æ ‡ç­¾ï¼‰
        2. å·¥å…·å“åº”ç»“æœï¼ˆä¿ç•™<tool_response>æ ‡ç­¾ï¼‰

        é‡è¦ï¼šä¿æŒåŸå§‹æ ‡ç­¾æ ¼å¼ï¼Œä¸åšä»»ä½•è½¬æ¢ï¼

        Args:
            messages: ReActæ¶ˆæ¯å†å²

        Returns:
            å®Œæ•´çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        context_parts = []

        for message in messages:
            role = message.get("role", "")
            content = message.get("content", "")

            if role == "assistant":
                # âœ… ä¿®å¤ï¼šç›´æ¥ä¿ç•™å®Œæ•´çš„assistantå“åº”ï¼Œä¸åšä»»ä½•è½¬æ¢
                # åŒ…å«<think>ã€<tool_call>ã€<answer>ç­‰æ‰€æœ‰æ ‡ç­¾
                if content.strip():
                    context_parts.append(content.strip())

            elif role == "user":
                # æå–å·¥å…·å“åº”ï¼ˆä¿ç•™<tool_response>æ ‡ç­¾ï¼‰
                if '<tool_response>' in content and '</tool_response>' in content:
                    context_parts.append(content.strip())

        full_context = "\n\n".join(context_parts)

        return full_context

    def _should_terminate(self) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ç»ˆæ­¢

        Returns:
            æ˜¯å¦åº”è¯¥ç»ˆæ­¢ä»»åŠ¡
        """
        if not self.insight_doc:
            return False

        # å¦‚æœæ²¡æœ‰å¾…åŠä»»åŠ¡ä¸”æ‰€æœ‰å·²å®Œæˆä»»åŠ¡éƒ½æˆåŠŸï¼Œåˆ™ç»ˆæ­¢
        no_pending = not self.insight_doc.current_task
        all_success = all(
            task.status == "æˆåŠŸ"
            for task in self.insight_doc.completed_tasks
        ) if self.insight_doc.completed_tasks else True

        return no_pending and all_success

    def _display_complete_memory(self):
        """æ˜¾ç¤ºå®Œæ•´çš„Memory Bankè®°å¿†"""

        # 1. Query Graphå±•ç¤º
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š Query Graph - Semantic Memory Graph")
        logger.info("=" * 80)
        logger.info(f"Total nodes: {self.query_graph.get_node_count()}")
        logger.info(f"Total edges: {self.query_graph.get_edge_count()}")
        logger.info("")

        for i, node in enumerate(self.query_graph.get_all_nodes(), 1):
            logger.info(f"Node {i}:")
            logger.info(f"  ID: {node.id}")
            logger.info(f"  Topic: {node.context}")
            logger.info(f"  Keywords: {', '.join(node.keywords)}")
            logger.info(f"  Summary: {node.summary[:200]}{'...' if len(node.summary) > 200 else ''}")
            logger.info(f"  Neighbors: {len(node.links)}")
            if node.links:
                logger.info(f"  Linked node IDs: {', '.join([nid[:8] for nid in node.links[:3]])}{'...' if len(node.links) > 3 else ''}")
            logger.info("-" * 80)

        # 2. Interaction Treeå±•ç¤º
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“š Interaction Tree - Interaction History")
        logger.info("=" * 80)
        logger.info(f"Total entries: {self.interaction_tree.get_total_entries()}")
        logger.info(f"Linked nodes: {len(self.interaction_tree.get_nodes_with_entries())}")
        logger.info("")

        for node_id in self.interaction_tree.get_nodes_with_entries():
            text = self.interaction_tree.get_entry(node_id)
            logger.info(f"Node ID: {node_id[:8]}...")
            if text:
                logger.info(f"  Text: {text[:150]}{'...' if len(text) > 150 else ''}")
            logger.info("-" * 80)

        # 3. Insight Docå±•ç¤º
        if self.insight_doc:
            logger.info("\n" + "=" * 80)
            logger.info("ğŸ“ Insight Doc - Task Status")
            logger.info("=" * 80)
            logger.info(f"Task goal: {self.insight_doc.task_goal}")
            logger.info(f"Completed tasks: {len(self.insight_doc.completed_tasks)}")
            logger.info("")

            for i, task in enumerate(self.insight_doc.completed_tasks, 1):
                logger.info(f"Task {i}:")
                logger.info(f"  Type: {task.type.value}")
                logger.info(f"  Description: {task.description}")
                logger.info(f"  Status: {task.status}")
                logger.info(f"  Context: {task.context}")
                logger.info("-" * 40)

            logger.info(f"Current task: {self.insight_doc.current_task if self.insight_doc.current_task else '(none)'}")
            logger.info("=" * 80)

    def export_memory(self, filepath: str):
        """
        å¯¼å‡ºè®°å¿†åˆ°JSONæ–‡ä»¶

        Args:
            filepath: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        import json

        memory_data = {
            "insight_doc": self.insight_doc.to_dict() if self.insight_doc else None,
            "query_graph": self.query_graph.to_dict(),
            "interaction_tree": self.interaction_tree.to_dict()
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(memory_data, f, ensure_ascii=False, indent=2)

        logger.info(f"Memory exported to: {filepath}")

    def load_memory(self, filepath: str):
        """
        ä»JSONæ–‡ä»¶åŠ è½½è®°å¿†

        Args:
            filepath: è¾“å…¥æ–‡ä»¶è·¯å¾„
        """
        import json

        with open(filepath, 'r', encoding='utf-8') as f:
            memory_data = json.load(f)

        if memory_data.get("insight_doc"):
            self.insight_doc = InsightDoc.from_dict(memory_data["insight_doc"])

        self.query_graph = QueryGraph.from_dict(memory_data["query_graph"])
        self.interaction_tree = InteractionTree.from_dict(memory_data["interaction_tree"])

        logger.info(f"Memory loaded from file: {filepath}")

    def __repr__(self) -> str:
        """è¿”å›Memory Bankæ‘˜è¦"""
        return (
            f"MemoryBank("
            f"nodes={self.query_graph.get_node_count()}, "
            f"edges={self.query_graph.get_edge_count()}, "
            f"entries={self.interaction_tree.get_total_entries()})"
        )
