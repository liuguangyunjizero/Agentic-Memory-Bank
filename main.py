"""
Agentic Memory Bank - å‘½ä»¤è¡Œæ¥å£

ç®€åŒ–ç‰ˆï¼šé»˜è®¤æ˜¾ç¤ºå®Œæ•´çš„ReActäº¤äº’è¿‡ç¨‹

ç”¨æ³•ï¼š
  python main.py "Among CS conferences, in 2025, which conference has..."
  python main.py --file input.txt
  python main.py --interactive
"""

import sys
import argparse
import logging
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.memory_bank import MemoryBank
from src.config import Config


def setup_logging(verbose: bool = False):
    """
    é…ç½®æ—¥å¿—

    Args:
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯
    """
    level = logging.DEBUG if verbose else logging.WARNING

    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # å§‹ç»ˆç¦ç”¨ç¬¬ä¸‰æ–¹åº“çš„INFOæ—¥å¿—
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)
    logging.getLogger("sentence_transformers").setLevel(logging.WARNING)


def setup_display_hook():
    """
    è®¾ç½®LLMè°ƒç”¨çš„å®æ—¶æ˜¾ç¤ºé’©å­

    æ˜¾ç¤ºç­–ç•¥ï¼š
    - ReAct Agent: æ˜¾ç¤ºåŸå§‹å“åº”ï¼ˆä¿ç•™æ‰€æœ‰<think>ã€<tool_call>ç­‰æ ‡ç­¾ï¼‰
    - å…¶ä»–Agent: åªæ˜¾ç¤ºç®€å•æç¤º
    - å·¥å…·å†…éƒ¨è°ƒç”¨: ä¸æ˜¾ç¤º
    """
    from src.utils.llm_client import LLMClient

    # ä¿å­˜åŸå§‹æ–¹æ³•
    original_call = LLMClient.call

    def patched_call(self, messages, temperature=None, top_p=None, stop=None, max_tokens=None):
        """æ‹¦æˆªLLMè°ƒç”¨ï¼Œå®æ—¶æ˜¾ç¤ºäº¤äº’"""

        # åˆ¤æ–­Agentç±»å‹
        is_react = False
        agent_type = None

        # å¤„ç†å­—ç¬¦ä¸²æˆ–åˆ—è¡¨æ ¼å¼çš„messages
        if isinstance(messages, str):
            prompt_text = messages
            if 'ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰è®°å¿†å’Œå·¥å…·è®¿é—®èƒ½åŠ›çš„æ™ºèƒ½åŠ©æ‰‹' in prompt_text:
                is_react = True
                agent_type = "ReAct Agent"
            elif 'ä»»åŠ¡è§„åˆ’ä¸“å®¶' in prompt_text:
                agent_type = "Planning Agent"
            elif 'ä¸Šä¸‹æ–‡åˆ†ç±»ä¸“å®¶' in prompt_text:
                agent_type = "Classification Agent"
            elif 'ä¿¡æ¯ç»“æ„åŒ–ä¸“å®¶' in prompt_text:
                agent_type = "Structure Agent"
            elif 'è®°å¿†å…³ç³»åˆ†æä¸“å®¶' in prompt_text:
                agent_type = "Analysis Agent"
            elif 'è®°å¿†æ•´åˆä¸“å®¶' in prompt_text:
                agent_type = "Integration Agent"
            # å·¥å…·å†…éƒ¨è°ƒç”¨ - ä¸æ˜¾ç¤º
            elif 'extract relevant information' in prompt_text.lower() or 'summarize' in prompt_text.lower():
                agent_type = None
        elif isinstance(messages, list) and len(messages) > 0:
            system_msg = messages[0].get('content', '')
            if 'ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰è®°å¿†å’Œå·¥å…·è®¿é—®èƒ½åŠ›çš„æ™ºèƒ½åŠ©æ‰‹' in system_msg:
                is_react = True
                agent_type = "ReAct Agent"
            elif 'ä»»åŠ¡è§„åˆ’ä¸“å®¶' in system_msg:
                agent_type = "Planning Agent"
            elif 'ä¸Šä¸‹æ–‡åˆ†ç±»ä¸“å®¶' in system_msg:
                agent_type = "Classification Agent"
            elif 'ä¿¡æ¯ç»“æ„åŒ–ä¸“å®¶' in system_msg:
                agent_type = "Structure Agent"
            elif 'è®°å¿†å…³ç³»åˆ†æä¸“å®¶' in system_msg:
                agent_type = "Analysis Agent"
            elif 'è®°å¿†æ•´åˆä¸“å®¶' in system_msg:
                agent_type = "Integration Agent"

        # è°ƒç”¨åŸå§‹æ–¹æ³•
        response = original_call(self, messages, temperature, top_p, stop, max_tokens)

        # å®æ—¶æ˜¾ç¤º
        if agent_type:  # åªæ˜¾ç¤ºå·²è¯†åˆ«çš„Agent
            if is_react:
                # ReAct Agentï¼šæ˜¾ç¤ºåŸå§‹å†…å®¹ï¼ˆä¿ç•™æ‰€æœ‰æ ‡ç­¾ï¼‰
                print("\n" + "â”€" * 100)
                print(f"ğŸ¤– {agent_type}")
                print("â”€" * 100)
                print(response)  # åŸå§‹è¾“å‡ºï¼Œä¸åŠ å·¥
                print("â”€" * 100)
            else:
                # å…¶ä»–Agentï¼šåªæ˜¾ç¤ºç®€å•æç¤º
                print(f"\nğŸ¤– æ­£åœ¨è°ƒç”¨ {agent_type}...")

        return response

    # åº”ç”¨patch
    LLMClient.call = patched_call


def run_query(memory_bank: MemoryBank, query: str, output_file: str = None):
    """
    è¿è¡ŒæŸ¥è¯¢

    Args:
        memory_bank: MemoryBankå®ä¾‹
        query: æŸ¥è¯¢å­—ç¬¦ä¸²
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    print("\n" + "=" * 100)
    print("ğŸ“ ç”¨æˆ·è¾“å…¥:")
    print("=" * 100)
    print(query)
    print("=" * 100)

    # æ‰§è¡ŒæŸ¥è¯¢
    result = memory_bank.run(query)

    # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
    print("\n" + "=" * 100)
    print("âœ… æœ€ç»ˆç­”æ¡ˆ:")
    print("=" * 100)
    print(result["answer"])
    print("=" * 100)

    # æ˜¾ç¤ºç»Ÿè®¡
    print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    stats = result["stats"]
    print(f"  - æ‰§è¡Œè½®æ¬¡: {stats.get('iterations', 0)}")
    print(f"  - Query GraphèŠ‚ç‚¹: {stats.get('graph_nodes', 0)}")
    print(f"  - Query Graphè¾¹: {stats.get('graph_edges', 0)}")
    print(f"  - Interaction Treeæ¡ç›®: {stats.get('tree_entries', 0)}")
    print(f"  - å·²å®Œæˆä»»åŠ¡: {stats.get('completed_tasks', 0)}")

    # å¯¼å‡ºè®°å¿†ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if output_file:
        memory_bank.export_memory(output_file)
        print(f"\nğŸ’¾ è®°å¿†å·²å¯¼å‡ºåˆ°: {output_file}")


def run_interactive(memory_bank: MemoryBank):
    """
    äº¤äº’å¼æ¨¡å¼

    Args:
        memory_bank: MemoryBankå®ä¾‹
    """
    print("\n" + "=" * 100)
    print("  ğŸš€ Agentic Memory Bank - äº¤äº’å¼æ¨¡å¼")
    print("=" * 100)
    print("\nå‘½ä»¤:")
    print("  ç›´æ¥è¾“å…¥é—®é¢˜è¿›è¡ŒæŸ¥è¯¢")
    print("  'export <æ–‡ä»¶å>' - å¯¼å‡ºè®°å¿†")
    print("  'load <æ–‡ä»¶å>' - åŠ è½½è®°å¿†")
    print("  'stats' - æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯")
    print("  'quit' æˆ– 'exit' - é€€å‡º")
    print("=" * 100 + "\n")

    while True:
        try:
            # è¯»å–è¾“å…¥
            query = input("\n> ").strip()

            if not query:
                continue

            # å¤„ç†å‘½ä»¤
            if query.lower() in ["quit", "exit"]:
                print("å†è§ï¼")
                break

            elif query.lower().startswith("export"):
                parts = query.split(maxsplit=1)
                filename = parts[1] if len(parts) > 1 else "memory_export.json"
                memory_bank.export_memory(filename)
                print(f"ğŸ’¾ è®°å¿†å·²å¯¼å‡ºåˆ°: {filename}")

            elif query.lower().startswith("load"):
                parts = query.split(maxsplit=1)
                if len(parts) < 2:
                    print("ç”¨æ³•: load <æ–‡ä»¶å>")
                    continue
                filename = parts[1]
                memory_bank.load_memory(filename)
                print(f"ğŸ“¥ è®°å¿†å·²ä»æ–‡ä»¶åŠ è½½: {filename}")

            elif query.lower() == "stats":
                print("\nğŸ“Š å½“å‰ç»Ÿè®¡:")
                print(f"  - GraphèŠ‚ç‚¹æ•°: {memory_bank.query_graph.get_node_count()}")
                print(f"  - Graphè¾¹æ•°: {memory_bank.query_graph.get_edge_count()}")
                print(f"  - Interaction Treeæ¡ç›®æ•°: {memory_bank.interaction_tree.get_total_entries()}")

            else:
                # æ™®é€šæŸ¥è¯¢
                run_query(memory_bank, query)

        except KeyboardInterrupt:
            print("\n\nä¸­æ–­ã€‚å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Agentic Memory Bank - ä»£ç†å¼è®°å¿†é“¶è¡Œ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python main.py "Among CS conferences, in 2025, which conference has..."
  python main.py --file input.txt
  python main.py --interactive
  python main.py --interactive --debug  (æ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯)
        """
    )

    # è¾“å…¥æ–¹å¼
    parser.add_argument(
        "query",
        nargs="?",
        type=str,
        help="æŸ¥è¯¢å­—ç¬¦ä¸²ï¼ˆå¦‚æœä¸æŒ‡å®šåˆ™è¿›å…¥äº¤äº’æ¨¡å¼ï¼‰"
    )

    parser.add_argument(
        "--file", "-f",
        type=str,
        help="ä»æ–‡ä»¶è¯»å–æŸ¥è¯¢"
    )

    parser.add_argument(
        "--interactive", "-i",
        action="store_true",
        help="äº¤äº’å¼æ¨¡å¼"
    )

    # è¾“å‡ºé€‰é¡¹
    parser.add_argument(
        "--output", "-o",
        type=str,
        help="è¾“å‡ºè®°å¿†åˆ°JSONæ–‡ä»¶"
    )

    # åŠ è½½è®°å¿†
    parser.add_argument(
        "--load",
        type=str,
        help="ä»JSONæ–‡ä»¶åŠ è½½è®°å¿†"
    )

    # è°ƒè¯•é€‰é¡¹
    parser.add_argument(
        "--debug",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼ˆDEBUGçº§åˆ«æ—¥å¿—ï¼‰"
    )

    args = parser.parse_args()

    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•è¾“å…¥ï¼Œè‡ªåŠ¨è¿›å…¥äº¤äº’æ¨¡å¼
    if not args.query and not args.file and not args.interactive:
        args.interactive = True

    # é…ç½®æ—¥å¿—
    setup_logging(verbose=args.debug)

    # è®¾ç½®å®æ—¶æ˜¾ç¤ºé’©å­
    setup_display_hook()

    try:
        # åˆå§‹åŒ–Memory Bank
        print("\n" + "=" * 100)
        print("ğŸš€ åˆå§‹åŒ– Agentic Memory Bank...")
        print("=" * 100)
        config = Config()
        memory_bank = MemoryBank(config)
        print("âœ… åˆå§‹åŒ–å®Œæˆ")
        print(f"  - LLMæ¨¡å‹: {config.LLM_MODEL}")
        print(f"  - Embeddingæ¨¡å‹: {config.EMBEDDING_MODEL}")

        # åŠ è½½è®°å¿†ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.load:
            print(f"\nğŸ“¥ åŠ è½½è®°å¿†: {args.load}")
            memory_bank.load_memory(args.load)
            print("âœ… åŠ è½½å®Œæˆ")

        # æ‰§è¡Œæ¨¡å¼
        if args.interactive:
            run_interactive(memory_bank)
        elif args.file:
            with open(args.file, 'r', encoding='utf-8') as f:
                query = f.read()
            run_query(memory_bank, query, args.output)
        elif args.query:
            run_query(memory_bank, args.query, args.output)

    except Exception as e:
        print(f"\nâŒ è‡´å‘½é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
